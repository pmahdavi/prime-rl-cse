[project]
name = "prime-rl"
version = "0.1.0"
description = ""
readme = "README.md"
requires-python = "~=3.12.0"
dependencies = [
    "beartype>=0.21.0",
    "cydifflib>=1.2.0",
    "datasets>=4.0.0",
    "jaxtyping>=0.3.2",
    "liger-kernel>=0.5.10",
    "loguru>=0.7.3",
    "numpy>=2.2.6",
    "openai>=1.106.1",
    "pydantic>=1.10.13",
    "pydantic-settings>=2.10.1",
    "pylatexenc>=2.10",
    "tomli>=2.2.1",
    "torch>=2.8.0",
    "transformers>=4.56.0",
    "uvloop>=0.21.0",
    "vllm==0.10.1.1",
    "wandb>=0.20.1",
    "lovely-tensors>=0.1.18",
    "rich>=14.0.0",
    "tomli-w",
    "verifiers>=0.1.3",
    "textarena>=0.6.16",
    "nltk>=3.9.1",
    "math-verify>=0.8.0",
    "dion @ git+https://github.com/samsja/dion.git",
    "torchdata>=0.11.0",
    "accelerate>=1.10.1",
    "torchtitan",
    "blobfile>=3.0.0",
]

[project.scripts]
rl = "prime_rl.rl:main"
trainer = "prime_rl.trainer.rl.train:main"
orchestrator = "prime_rl.orchestrator.orchestrator:main"
inference = "prime_rl.inference.server:main"
sft = "prime_rl.trainer.sft.train:main"
eval = "prime_rl.eval.eval:main"

[project.optional-dependencies]
flash-attn = ["flash-attn>=2.8.3"]
flash-infer = ["flashinfer-python>=0.2.8rc1"]

vf = [
    "alphabet-sort>=0.1.5",
    "ascii-tree>=0.1.6",
    "pydantic-adherence>=0.1.3",
    "reverse-text>=0.1.4",
    "unscramble>=0.1.3",
    "skywork-math>=0.1.7",
    "deepscaler-math>=0.1.5",
    "acereason-math>=0.1.5",
    "hendrycks-math>=0.1.5",
    "intellect-math>=0.1.5",
    "aime2024>=0.1.11",
    "aime2025>=0.1.11",
    "math500>=0.1.10",
    "gpqa>=0.1.0",
    "livecodebench>=0.1.2.post0",
    "tau2 @ git+https://github.com/sierra-research/tau2-bench.git",
    "tau2_bench>=0.1.2.post0",
    "simpleqa>=0.1.1",
    "hle>=0.1.1",
]

[tool.uv]
no-build-isolation-package = ["flash-attn"]
prerelease = "allow"
override-dependencies = [
  "torch==2.8.0", # Temporary patch as vllm hasnt updated but needed by MoE
  "torchvision==0.23.0", # Temporary patch as vllm hasnt updated but needed by MoE
]

[tool.uv.sources]
torch = [{ index = "pytorch-cu128" }]
torchtitan = { git = "https://github.com/pytorch/torchtitan", rev = "a1fdd7e43694bbfeff5d6ad8ac738c067bb90d41" }

alphabet-sort = { index = "primeintellect" }
ascii-tree = { index = "primeintellect" }
pydantic-adherence = { index = "primeintellect" }
reverse-text = { index = "primeintellect" }
unscramble = { index = "primeintellect" }
skywork-math = { index = "primeintellect" }
deepscaler-math = { index = "primeintellect" }
acereason-math = { index = "primeintellect" }
hendrycks-math = { index = "primeintellect" }
intellect-math = { index = "primeintellect" }
aime2024 = { index = "primeintellect" }
aime2025 = { index = "primeintellect" }
math500 = { index = "primeintellect" }
livecodebench = { index = "primeintellect" }
tau2_bench = { index = "primeintellect" }
simpleqa = { index = "primeintellect" }
hle = { index = "primeintellect" } 

[[tool.uv.index]]
name = "primeintellect"
url = "https://hub.primeintellect.ai/primeintellect/simple/"

[[tool.uv.index]]
name = "pytorch-cu128"
url = "https://download.pytorch.org/whl/test/cu128"
explicit = true

[dependency-groups]
dev = [
    "ipykernel>=6.29.5",
    "ipywidgets>=8.1.7",
    "pre-commit>=4.2.0",
    "pytest>=8.4.1",
    "ruff>=0.12.1",
]


[tool.ruff.lint]
select = ["F", "I"]
ignore = ["F722", "F821"] # Need to ignore for jaxtyping (https://docs.kidger.site/jaxtyping/faq/)

[tool.ruff]
line-length = 120

[tool.pytest.ini_options]
addopts = "--strict-markers"
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "gpu: marks tests as gpu (deselect with '-m \"not gpu\"')",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.metadata]
allow-direct-references = true
